{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23R0Z9RojXYW"
   },
   "source": [
    "<!-- TODO(ccy): split this notebook into (1) a beginner friendly notebook that\n",
    "     avoids directly calling into TFX libraries and (2) an advanced notebook\n",
    "     or notebooks that delve more deeply into each component, along with their\n",
    "     underlying libraries. -->\n",
    "# TFX Iterative Development Example\n",
    "This notebook demonstrates how to use Jupyter notebooks for TFX iterative development.  Here, we walk through the Chicago Taxi example in an interactive Jupyter notebook.\n",
    "\n",
    "Note: this notebook along with its associated APIs are **experimental** and are\n",
    "in active development.  Major changes in functionality, behavior and\n",
    "presentation are expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GivNBNYjb3b"
   },
   "source": [
    "## Setup\n",
    "First, install dependencies, import modules, set up paths, and download data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZOYTt1RW4TK"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-ePgV0Lj68Q"
   },
   "source": [
    "### Import packages\n",
    "We import necessary packages, including standard TFX component classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIqpWK9efviJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/envs/tfx/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Some syntactic constructs of Python 3 are not yet fully supported by Apache Beam.\n",
      "  'Some syntactic constructs of Python 3 are not yet fully supported by '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/tfx/lib/python3.6/site-packages/tfx/components/transform/executor.py:57: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/tfx/lib/python3.6/site-packages/tfx/components/transform/executor.py:57: from_feature_spec (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "from_feature_spec is a deprecated, use schema_utils.schema_from_feature_spec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "from tfx.components.evaluator.component import Evaluator\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.components.example_validator.component import ExampleValidator\n",
    "from tfx.components.model_validator.component import ModelValidator\n",
    "from tfx.components.pusher.component import Pusher\n",
    "from tfx.components.schema_gen.component import SchemaGen\n",
    "from tfx.components.statistics_gen.component import StatisticsGen\n",
    "from tfx.components.trainer.component import Trainer\n",
    "from tfx.components.transform.component import Transform\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import evaluator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.proto.evaluator_pb2 import SingleSlicingSpec\n",
    "from tfx.utils.dsl_utils import csv_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ChG4HSd1Tgq"
   },
   "source": [
    "### Load custom extensions\n",
    "Use cell magic `%%skip_for_export` to denote cells to skip during export to pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgxtWZ581Tgr"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tfx.orchestration.interactive.notebook_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e6ece4b31123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfx.orchestration.interactive.notebook_extensions.skip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</root/miniconda3/envs/tfx/lib/python3.6/site-packages/decorator.py:decorator-gen-64>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfx/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tfx.orchestration.interactive.notebook_extensions'"
     ]
    }
   ],
   "source": [
    "%load_ext tfx.orchestration.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufJKQ6OvkJlY"
   },
   "source": [
    "### Set up pipeline paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad5JLpKbf6sN"
   },
   "outputs": [],
   "source": [
    "# Set up paths.\n",
    "\n",
    "_tfx_root = tfx.__path__[0]\n",
    "_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n",
    "# Path which can be listened to by the model server.  Pusher will output the\n",
    "# trained model here.\n",
    "_serving_model_dir = os.path.join(\n",
    "    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n",
    "\n",
    "# Python module file to inject customized logic into the TFX components. The\n",
    "# Transform and Trainer both require user-defined functions to run successfully.\n",
    "_taxi_module_file = os.path.join(_taxi_root, 'taxi_utils.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2cMMAbSkGfX"
   },
   "source": [
    "### Download example data\n",
    "We download the sample dataset for use in our TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BywX6OUEhAqn"
   },
   "outputs": [],
   "source": [
    "# Download the example data.\n",
    "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
    "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
    "with open(os.path.join(_data_root, 'data.csv'), 'wb') as f:\n",
    "    contents = urllib.request.urlopen(DATA_PATH).read()\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ONIE_hdkPS4"
   },
   "source": [
    "## Create the InteractiveContext\n",
    "We now create the interactive context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Rh6K5sUf9dd"
   },
   "outputs": [],
   "source": [
    "# Here, we create an InteractiveContext using default parameters. This will\n",
    "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
    "# To use your own pipeline root or database, the optional properties\n",
    "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
    "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
    "# notebook.\n",
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdQWxfsVkzdJ"
   },
   "source": [
    "## Run TFX components interactively\n",
    "Next, we construct TFX components and run each one interactively using within the interactive session to obtain `ExecutionResult` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9fwt9gQk3BR"
   },
   "source": [
    "### ExampleGen\n",
    "`ExampleGen` brings data into the TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyXjuMt8f-9u"
   },
   "outputs": [],
   "source": [
    "# Use the packaged CSV input data.\n",
    "examples = csv_input(_data_root)\n",
    "\n",
    "# Brings data into the pipeline or otherwise joins/converts training data.\n",
    "example_gen = CsvExampleGen(input=examples)\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csM6BFhtk5Aa"
   },
   "source": [
    "### StatisticsGen (using Tensorflow Data Validation)\n",
    "`StatisticsGen` computes statistics for visualization and example validation. This uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0tl75TMW3DR"
   },
   "source": [
    "#### Run TFDV statistics computation using the StatisticsGen component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MAscCCYWgA-9"
   },
   "outputs": [],
   "source": [
    "# Computes statistics over data for visualization and example validation.\n",
    "statistics_gen = StatisticsGen(\n",
    "    examples=example_gen.outputs['examples'])\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLI6cb_5WugZ"
   },
   "source": [
    "#### Visualize the statistics result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLjXy7K6Tp_G"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLKLTO9Nk60p"
   },
   "source": [
    "### SchemaGen (using Tensorflow Data Validation)\n",
    "`SchemaGen` generates a schema for your data based on computed statistics. This component also uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0xvulenXSK3"
   },
   "source": [
    "#### Run TFDV schema inference using the SchemaGen component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygQvZ6hsiQ_J"
   },
   "outputs": [],
   "source": [
    "# Generates schema based on statistics files.\n",
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)\n",
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zi6TxTUKXM6b"
   },
   "source": [
    "#### Visualize the inferred schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec9vqDXpXeMb"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1qcUuO9k9f8"
   },
   "source": [
    "### ExampleValidator\n",
    "`ExampleValidator` performs anomaly detection based on computed statistics and your data schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONg1bt57gVna"
   },
   "source": [
    "#### Run TFDV data validation using the ExampleValidation component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRlRUuGgiXks"
   },
   "outputs": [],
   "source": [
    "# Performs anomaly detection based on statistics and data schema.\n",
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "855mrHgJcoer"
   },
   "source": [
    "#### Visualize the detected anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDyAAozQcrk3"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPViEz5RlA36"
   },
   "source": [
    "### Transform\n",
    "`Transform` performs data transformations and feature engineering which are kept in sync for training and serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgbmZr3sgbWW"
   },
   "source": [
    "#### Run the Transform component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHfhth_GiZI9"
   },
   "outputs": [],
   "source": [
    "# Performs transformations and feature engineering in training and serving.\n",
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=_taxi_module_file)\n",
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBJFtnl6lCg9"
   },
   "source": [
    "### Trainer\n",
    "`Trainer` trains your custom model using TF-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "429-vvCWibO0"
   },
   "outputs": [],
   "source": [
    "# Uses user-provided Python function that implements a model using TF-Learn.\n",
    "trainer = Trainer(\n",
    "    module_file=_taxi_module_file,\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmPftrv0lEQy"
   },
   "source": [
    "### Evaluator (using Tensorflow Model Analysis)\n",
    "The `Evaluator` computes evaluation statistics over features of your model using [Tensorflow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started). In this section, we run TFMA in our TFX pipeline and then visualize the results to analyze the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGcid3lXJsBf"
   },
   "source": [
    "#### Run TFMA using the Evaluator component\n",
    "\n",
    "Here, we first define slicing specs for analyzing our data. Next, we run TFMA using these specs to generate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVhfzzh9PDEx"
   },
   "outputs": [],
   "source": [
    "# An empty slice spec means the overall slice, that is, the whole dataset.\n",
    "OVERALL_SLICE_SPEC = evaluator_pb2.SingleSlicingSpec()\n",
    "\n",
    "# Data can be sliced along a feature column\n",
    "# In this case, data is sliced along feature column trip_start_hour.\n",
    "FEATURE_COLUMN_SLICE_SPEC = evaluator_pb2.SingleSlicingSpec(\n",
    "    column_for_slicing=['trip_start_hour'])\n",
    "\n",
    "# Data can be sliced by crossing feature columns\n",
    "# In this case, slices are computed for trip_start_day x trip_start_month.\n",
    "FEATURE_COLUMN_CROSS_SPEC = evaluator_pb2.SingleSlicingSpec(\n",
    "    column_for_slicing=['trip_start_day', 'trip_start_month'])\n",
    "\n",
    "ALL_SPECS = [\n",
    "    OVERALL_SLICE_SPEC,\n",
    "    FEATURE_COLUMN_SLICE_SPEC,\n",
    "    FEATURE_COLUMN_CROSS_SPEC,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zjcx8g6mihSt"
   },
   "outputs": [],
   "source": [
    "# Use TFMA to compute a evaluation statistics over features of a model.\n",
    "evaluator = Evaluator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model_exports=trainer.outputs['model'],\n",
    "    feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(\n",
    "        specs=ALL_SPECS\n",
    "    ))\n",
    "context.run(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9hGoEiIQROd"
   },
   "source": [
    "#### Show the TFMA visualization for the default slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U729j5X5QQUQ"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(evaluator.outputs['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2VKvr3NJwii"
   },
   "source": [
    "#### Get the TFMA output result path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyis6iy0HLdi"
   },
   "outputs": [],
   "source": [
    "PATH_TO_RESULT = evaluator.outputs['output'].get()[0].uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9YNBXsQKW63"
   },
   "source": [
    "#### Import TFMA and load the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SeuBh8aHZ9S"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdLc25OnKs0G"
   },
   "source": [
    "#### Visualization: Slicing Metrics\n",
    "\n",
    "To see the slices, either use the name of the column (by setting slicing_column) or provide a tfma.slicer.SingleSliceSpec (by setting slicing_spec). If neither is provided, an overall visualization will be displayed.\n",
    "\n",
    "The default visualization is the **slice overview** when the number of slices is small. It shows the value of a metric for each slice, sorted by the another metric. It is also possible to set a threshold to filter out slices with smaller weights.\n",
    "\n",
    "This view also supports the **metrics histogram** as an alternative visualization. It is also the default view when the number of slices is large. The results will be divided into buckets and the number of slices / total weights / both can be visualized. Slices with small weights can be filtered out by setting the threshold. Further filtering can be applied by dragging the grey band. To reset the range, double click the band. Filtering can be used to remove outliers in the visualization and the metrics table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYvXSBANHdmZ"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "# Show data sliced along feature column trip_start_hour.\n",
    "tfma.view.render_slicing_metrics(\n",
    "    tfma_result, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGADc5R7Q8yo"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "# Show metrics sliced by 'trip_start_day' x 'trip_start_month'.\n",
    "tfma.view.render_slicing_metrics(\n",
    "    tfma_result,\n",
    "    slicing_spec=tfma.slicer.SingleSliceSpec(\n",
    "        columns=['trip_start_day','trip_start_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFvfzTTZL_0a"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "# Show overall metrics.\n",
    "tfma.view.render_slicing_metrics(tfma_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Mtpg8jxFYDl"
   },
   "source": [
    "#### Visualization: Time Series\n",
    "\n",
    "If multiple evaluation runs were performed, they can be visualized in a time series view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLeJb-LXFiol"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "# Note that we are showing the same set of results three times here. Please replace\n",
    "# PATH_TO_RESULT_1 ~ 3 as more results become available.\n",
    "\n",
    "PATH_TO_RESULT_1 = PATH_TO_RESULT\n",
    "PATH_TO_RESULT_2 = PATH_TO_RESULT\n",
    "PATH_TO_RESULT_3 = PATH_TO_RESULT\n",
    "\n",
    "result_1 = tfma.load_eval_result(PATH_TO_RESULT_1)\n",
    "result_2 = tfma.load_eval_result(PATH_TO_RESULT_2)\n",
    "result_3 = tfma.load_eval_result(PATH_TO_RESULT_3)\n",
    "\n",
    "eval_results = tfma.make_eval_results([result_1, result_2, result_3],\n",
    "                                      tfma.constants.MODEL_CENTRIC_MODE)\n",
    "tfma.view.render_time_series(eval_results, tfma.slicer.SingleSliceSpec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76Mil-7FlF_y"
   },
   "source": [
    "### ModelValidator\n",
    "`ModelValidator` performs validation of your candidate model compared to a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXk1MA7sijCr"
   },
   "outputs": [],
   "source": [
    "# Performs quality validation of a candidate model (compared to a baseline).\n",
    "model_validator = ModelValidator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model=trainer.outputs['model'])\n",
    "context.run(model_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8DYekCZlHfj"
   },
   "source": [
    "### Pusher\n",
    "`Pusher` checks whether a model has passed validation, and if so, pushes the model to a file destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r45nQ69eikc9"
   },
   "outputs": [],
   "source": [
    "# Checks whether the model passed the validation steps and pushes the model\n",
    "# to a file destination if check passed.\n",
    "pusher = Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=model_validator.outputs['blessing'],\n",
    "    push_destination=pusher_pb2.PushDestination(\n",
    "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "            base_directory=_serving_model_dir)))\n",
    "context.run(pusher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGNDOG1o1Tht"
   },
   "source": [
    "## Export to pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Obxof4O71Thu"
   },
   "source": [
    "### Mount Google Drive (Colab).\n",
    "Save a copy of your notebook in Google Drive if you haven't already, then run the following cell to mount drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CH8yu7Un1Thu"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export #@title Run to mount Google Drive. { display-mode: \"form\" }\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  # Colab.\n",
    "  from google.colab import drive\n",
    "\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CO7erulbvUNi"
   },
   "outputs": [],
   "source": [
    "#@title Select a runner type. { display-mode: \"form\" }\n",
    "_runner_type = 'beam' #@param [\"beam\", \"airflow\"]\n",
    "_pipeline_name = 'chicago_taxi_%s' % _runner_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d64gdS2u1Thw"
   },
   "source": [
    "### Set up notebook/export paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_dZL1lS1Thx"
   },
   "outputs": [],
   "source": [
    "# TODO(USER).\n",
    "\n",
    "# Colab example.\n",
    "# TODO(USER): Update notebook file path and export dir.\n",
    "_notebook_filepath = (\n",
    "    '/content/drive/My Drive/Colab Notebooks/taxi_pipeline_interactive.ipynb')\n",
    "_export_dir = '/content'\n",
    "\n",
    "# Jupyter example.\n",
    "# _notebook_filepath = os.path.join(os.getcwd(),\n",
    "#                                   'taxi_pipeline_interactive.ipynb')\n",
    "# _export_dir = os.getcwd()\n",
    "\n",
    "# TODO(USER): Paths for exported pipeline.\n",
    "_tfx_root = os.path.join(os.environ['HOME'], 'tfx')\n",
    "_taxi_root = os.path.join(os.environ['HOME'], 'taxi')\n",
    "_serving_model_dir = os.path.join(_taxi_root, 'serving_model')\n",
    "_data_root = os.path.join(_taxi_root, 'data', 'simple')\n",
    "\n",
    "_pipeline_root = os.path.join(_tfx_root, 'pipelines', _pipeline_name)\n",
    "# Sqlite ML-metadata db path.\n",
    "_metadata_path = os.path.join(_tfx_root, 'metadata', _pipeline_name,\n",
    "                              'metadata.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stNBJAIPvUNq"
   },
   "source": [
    "### Specify components in exported pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNc0Iks2vUNq"
   },
   "outputs": [],
   "source": [
    "components = [\n",
    "    # TODO(USER): Specify components to be part of the exported pipeline.\n",
    "    example_gen, statistics_gen, schema_gen, example_validator, transform,\n",
    "    trainer, evaluator, model_validator, pusher\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nATTNYZ1Thy"
   },
   "source": [
    "### Save your notebook, then run the next cell to export a pipeline to run on Beam/Airflow/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsfNFi6iHMSp"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export #@title Run cell to export pipeline. { display-mode: \"form\" }\n",
    "\n",
    "if get_ipython().magics_manager.auto_magic:\n",
    "  print('Warning: %automagic is ON. Line magics specified without the % prefix '\n",
    "        'will not be scrubbed during export to pipeline.')\n",
    "\n",
    "export_filepath = os.path.join(_export_dir, 'export_%s.py' % _pipeline_name)\n",
    "context.export_to_pipeline(notebook_filepath=_notebook_filepath,\n",
    "                           export_filepath=export_filepath,\n",
    "                           runner_type=_runner_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AL-eHsdV1Th3"
   },
   "source": [
    "### Download exported script from Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "FeRJyHly1Th3"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export #@title Run cell to download exported script.\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import files\n",
    "\n",
    "  files.download(export_filepath)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//experimental/users/vemmadi/colab:tfx_notebook",
    "kind": "private"
   },
   "name": "taxi_pipeline_interactive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
